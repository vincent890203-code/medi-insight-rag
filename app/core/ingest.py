# app/core/ingest.py

import os
import shutil
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
# âŒ ç§»é™¤ Google
# âœ… æ”¹ç”¨ HuggingFace æœ¬åœ°æ¨¡å‹
from langchain_huggingface import HuggingFaceEmbeddings 
from langchain_chroma import Chroma

load_dotenv()

DATA_PATH = "data/"
DB_PATH = "chroma_db"

def ingest_documents():
    print(f"ğŸ”„ [Local Embedding ç‰ˆ] æº–å‚™é–‹å§‹...")

    # 1. æ¸…ç†èˆŠè³‡æ–™åº«
    if os.path.exists(DB_PATH):
        print("ğŸ§¹ æ¸…ç†èˆŠè³‡æ–™åº«...")
        shutil.rmtree(DB_PATH)
    
    # 2. è®€å– PDF
    documents = []
    for file in os.listdir(DATA_PATH):
        if file.endswith(".pdf"):
            pdf_path = os.path.join(DATA_PATH, file)
            print(f"ğŸ“– è®€å–æª”æ¡ˆ: {file}")
            loader = PyPDFLoader(pdf_path)
            documents.extend(loader.load())

    if not documents:
        print("âš ï¸ ç„¡æª”æ¡ˆï¼ŒçµæŸã€‚")
        return

    # 3. åˆ‡åˆ†æ–‡å­—
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    chunks = text_splitter.split_documents(documents)
    print(f"âœ‚ï¸  å…±åˆ‡åˆ†ç‚º {len(chunks)} å€‹å€å¡Šã€‚")

    # 4. åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹ (é—œéµæ­¥é©Ÿ)
    print("ğŸ§  æ­£åœ¨è¼‰å…¥ HuggingFace æœ¬åœ°æ¨¡å‹ (é¦–æ¬¡åŸ·è¡Œæœƒä¸‹è¼‰æ¨¡å‹ï¼Œç´„ 100MB)...")
    
    # ä½¿ç”¨æ¨™æº–çš„è¼•é‡ç´šæ¨¡å‹
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    
    # 5. å¿«é€Ÿå…¥åº« (å› ç‚ºæ˜¯æœ¬åœ°ç«¯ï¼Œä¸ç”¨ sleepï¼Œå¯ä»¥ç›´æ¥è¡)
    print("ğŸš€ é–‹å§‹é«˜é€Ÿå‘é‡åŒ– (Local Compute)...")
    
    vector_store = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory=DB_PATH
    )

    print(f"ğŸ‰ æˆåŠŸï¼æ‰€æœ‰è³‡æ–™å·²å­˜å…¥ {DB_PATH}")
    print("ğŸ’¡ æç¤ºï¼šå› ç‚ºä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œä»¥å¾ŒæŸ¥è©¢éƒ½ä¸éœ€è¦ Embedding çš„ API Key äº†ï¼")

if __name__ == "__main__":
    ingest_documents()