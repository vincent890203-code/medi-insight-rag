import os
import sys
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

# 1. è¨­å®šç’°å¢ƒ
load_dotenv()

# è¨­å®šè³‡æ–™è·¯å¾‘
# ç‚ºäº†é…åˆ web_ui.py åœ¨æ ¹ç›®éŒ„åŸ·è¡Œï¼Œé€™è£¡çš„è·¯å¾‘ç›¸å°æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„
DATA_PATH = "data/" 
DB_PATH = "faiss_index"

def create_vector_db():
    """
    è®€å– PDF ä¸¦å»ºç«‹ FAISS å‘é‡è³‡æ–™åº«ã€‚
    å›å‚³å€¼: (success: bool, message: str)
    """
    log_messages = [] # ç”¨ä¾†æ”¶é›†åŸ·è¡Œéç¨‹çš„è¨Šæ¯
    
    log_messages.append(f"ğŸ“‚ æª¢æŸ¥è³‡æ–™ä¾†æºè·¯å¾‘: {DATA_PATH} ...")
    
    # æª¢æŸ¥è·¯å¾‘æ˜¯å¦å­˜åœ¨
    if not os.path.exists(DATA_PATH):
        error_msg = f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è·¯å¾‘ {DATA_PATH}"
        print(error_msg)
        return False, error_msg

    # 2. æ™ºæ…§è¼‰å…¥
    documents = []
    
    try:
        if os.path.isfile(DATA_PATH):
            # å–®ä¸€æª”æ¡ˆæ¨¡å¼
            loader = PyPDFLoader(DATA_PATH)
            documents.extend(loader.load())
            log_messages.append(f"  - è¼‰å…¥å–®ä¸€æª”æ¡ˆ: {DATA_PATH}")
            
        elif os.path.isdir(DATA_PATH):
            # è³‡æ–™å¤¾æ¨¡å¼ (æƒææ‰€æœ‰ PDF)
            log_messages.append(f"  - æƒæè³‡æ–™å¤¾ä¸­...")
            pdf_files = [f for f in os.listdir(DATA_PATH) if f.endswith(".pdf")]
            
            if not pdf_files:
                return False, "âš ï¸ è³‡æ–™å¤¾å…§æ²’æœ‰ PDF æª”æ¡ˆï¼Œè«‹å…ˆç¢ºèª data/ ç›®éŒ„ã€‚"
                
            for file in pdf_files:
                pdf_path = os.path.join(DATA_PATH, file)
                loader = PyPDFLoader(pdf_path)
                documents.extend(loader.load())
                log_messages.append(f"  - è¼‰å…¥: {file}")
    except Exception as e:
        return False, f"âŒ è®€å– PDF å¤±æ•—: {str(e)}"
    
    if not documents:
        return False, "âš ï¸ æ²’è®€åˆ°ä»»ä½•å…§å®¹ï¼Œè«‹æª¢æŸ¥ PDF æ˜¯å¦åŠ å¯†æˆ–ç©ºç™½ã€‚"

    log_messages.append(f"âœ… PDF è®€å–æˆåŠŸï¼Œå…± {len(documents)} é ")

    # 3. åˆ‡å‰²æ–‡å­—
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    docs = text_splitter.split_documents(documents)
    log_messages.append(f"ğŸ”ª æ–‡å­—åˆ‡å‰²å®Œæˆï¼šå…±ç”¢ç”Ÿ {len(docs)} å€‹ç‰‡æ®µ (Chunks)")

    # 4. è½‰æˆå‘é‡
    log_messages.append("ğŸ§  æ­£åœ¨è¼‰å…¥ Embedding æ¨¡å‹ (all-MiniLM-L6-v2)...")
    try:
        embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    except Exception as e:
        return False, f"âŒ Embedding æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}"

    # 5. å»ºç«‹ä¸¦å„²å­˜è³‡æ–™åº« (FAISS)
    log_messages.append(f"ğŸ’¾ æ­£åœ¨å»ºç«‹å‘é‡ç´¢å¼•ä¸¦å­˜æª”è‡³ {DB_PATH}...")
    try:
        vector_store = FAISS.from_documents(docs, embeddings)
        vector_store.save_local(DB_PATH)
    except Exception as e:
        return False, f"âŒ FAISS å„²å­˜å¤±æ•—: {str(e)}"

    final_msg = "\n".join(log_messages)
    print(final_msg) # ä¿ç•™çµ‚ç«¯æ©Ÿè¼¸å‡ºæ–¹ä¾¿é™¤éŒ¯
    return True, final_msg

if __name__ == "__main__":
    # å¦‚æœç›´æ¥åŸ·è¡Œæ­¤è…³æœ¬ï¼Œåªå°å‡ºçµæœ
    success, msg = create_vector_db()
    if not success:
        sys.exit(1)