import os
import sys
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS # <--- é—œéµæ”¹è®Šï¼šæˆ‘å€‘ç”¨ FAISS

# 1. è¨­å®šç’°å¢ƒ
load_dotenv()

# è¨­å®šè³‡æ–™è·¯å¾‘
# ç‚ºäº†è®“ä½ ç¨å¾Œä¸ç”¨æ”¹ä¾†æ”¹åŽ»ï¼Œæˆ‘å¯«äº†é˜²å‘†ï¼š
# å¦‚æžœ data æ˜¯è³‡æ–™å¤¾ï¼Œå®ƒæœƒè®€è³‡æ–™å¤¾ï¼›å¦‚æžœæ˜¯æª”æ¡ˆï¼Œå®ƒè®€æª”æ¡ˆã€‚
DATA_PATH = "data/patient_report_001.pdf" 
DB_PATH = "faiss_index"

def create_vector_db():
    print(f"ðŸ“„ æ­£åœ¨æº–å‚™è®€å–: {DATA_PATH} ...")
    
    # æª¢æŸ¥è·¯å¾‘æ˜¯å¦å­˜åœ¨
    if not os.path.exists(DATA_PATH):
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è·¯å¾‘ {DATA_PATH}")
        return

    # 2. æ™ºæ…§è¼‰å…¥ (ä¿®æ­£åŽŸæœ¬çš„ Bug)
    documents = []
    if os.path.isfile(DATA_PATH):
        # å¦‚æžœæ˜¯å–®ä¸€æª”æ¡ˆ (ä½ çš„æƒ…æ³)
        loader = PyPDFLoader(DATA_PATH)
        documents.extend(loader.load())
    elif os.path.isdir(DATA_PATH):
        # å¦‚æžœæ˜¯è³‡æ–™å¤¾ (æœªä¾†çš„æ“´å……æ€§)
        for file in os.listdir(DATA_PATH):
            if file.endswith(".pdf"):
                pdf_path = os.path.join(DATA_PATH, file)
                loader = PyPDFLoader(pdf_path)
                documents.extend(loader.load())
    
    if not documents:
        print("âš ï¸ æ²’è®€åˆ°ä»»ä½•å…§å®¹ï¼Œç¨‹å¼çµæŸã€‚")
        return

    print(f"âœ… æˆåŠŸè¼‰å…¥ï¼Œå…± {len(documents)} é ")

    # 3. åˆ‡å‰²æ–‡å­—
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    docs = text_splitter.split_documents(documents)
    print(f"ðŸ”ª å·²åˆ‡å‰²æˆ {len(docs)} å€‹ç‰‡æ®µ")

    # 4. è½‰æˆå‘é‡
    print("ðŸ§  æ­£åœ¨è¼‰å…¥ Embedding æ¨¡åž‹ (all-MiniLM-L6-v2)...")
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

    # 5. å»ºç«‹ä¸¦å„²å­˜è³‡æ–™åº« (FAISS)
    print("ðŸ’¾ æ­£åœ¨å»ºç«‹å‘é‡ç´¢å¼•ä¸¦å­˜æª”...")
    # æ³¨æ„ï¼šé€™è£¡ç”¨ FAISS.from_documentsï¼Œä¸æ˜¯ Chroma
    vector_store = FAISS.from_documents(docs, embeddings)
    vector_store.save_local(DB_PATH)
    print(f"âœ… æˆåŠŸï¼FAISS å‘é‡è³‡æ–™åº«å·²å„²å­˜è‡³: {DB_PATH}")

if __name__ == "__main__":
    create_vector_db()